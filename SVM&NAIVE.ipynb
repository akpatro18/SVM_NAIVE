{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Q1: What is a Support Vector Machine (SVM), and how does it work?\n",
        "\n",
        "Answer : A Support Vector Machine (SVM) is a supervised machine learning algorithm primarily used for classification (and also regression). SVM finds a decision boundary (a hyperplane) that best separates instances of different classes by maximizing the margin — the distance between the hyperplane and the nearest data points of any class. The nearest points that lie on the margin are called support vectors; they determine the position and orientation of the separating hyperplane.\n",
        "\n",
        "Key concepts and how SVM works:\n",
        "\n",
        "Linear separability and hyperplane\n",
        "\n",
        "In D-dimensional feature space, a hyperplane is a (D−1)-dimensional subspace that separates the space into two halves. For linearly separable data, SVM finds the hyperplane that separates classes with the maximum margin, which often gives better generalization.\n",
        "\n",
        "Margin maximization (primal/dual form)\n",
        "\n",
        "The optimization objective is to maximize the margin while ensuring that all points are correctly classified (for hard margin) or that misclassification penalties are minimized (for soft margin). This becomes a quadratic optimization problem solvable via convex optimization. The dual formulation expresses the solution as a linear combination of training points; only support vectors have nonzero coefficients.\n",
        "\n",
        "Soft margin & slack variables\n",
        "\n",
        "Real-world data are not perfectly separable; SVM introduces slack variables ξᵢ and a penalty parameter C to allow misclassifications while controlling the tradeoff between margin size and classification errors.\n",
        "\n",
        "Kernels and non-linear decision boundaries\n",
        "\n",
        "For nonlinearly separable data, SVM can implicitly map inputs into higher-dimensional space using kernel functions (kernel trick) and find a linear separator there — corresponding to a nonlinear boundary in original space.\n",
        "\n",
        "Regularization and generalization\n",
        "\n",
        "The parameter C acts like a regularizer; small C → wider margin with more tolerance for misclassification (more regularization), large C → narrower margin prioritizing classification accuracy on training data.\n",
        "\n",
        "Advantages and limitations\n",
        "\n",
        "Advantages: effective in high-dimensional spaces, robust (max-margin), can use kernels, usually good generalization.\n",
        "\n",
        "Limitations: can be slow on very large datasets (training cost ~ O(n³) for naive solvers), needs careful kernel/parameter tuning, less interpretable.\n",
        "\n",
        "Common use cases\n",
        "\n",
        "Text classification (high dimensional sparse data), image classification, bioinformatics, and any binary classification tasks where maximizing margin is beneficial.\n",
        "\n",
        "Short mathematical sketch:\n",
        "Given labeled data (xᵢ, yᵢ), yᵢ ∈ {−1, +1}, SVM solves:\n",
        "\n",
        "Primal (soft margin):\n",
        "minimize (1/2)||w||² + C Σ ξᵢ\n",
        "subject to yᵢ (wᵀ xᵢ + b) ≥ 1 − ξᵢ, ξᵢ ≥ 0\n",
        "\n",
        "Dual (kernelized) uses Lagrange multipliers αᵢ and kernel K(xᵢ, xⱼ). Support vectors are points with αᵢ > 0.\n",
        "\n",
        "# Q2: Explain the difference between Hard Margin and Soft Margin SVM.\n",
        "\n",
        "Answer : Hard Margin SVM\n",
        "\n",
        "Applicable only when the training data are linearly separable without errors (no overlap between classes).\n",
        "\n",
        "The optimization seeks a hyperplane that classifies all training points correctly while maximizing the margin.\n",
        "\n",
        "Constraints: for all i, yᵢ(wᵀxᵢ + b) ≥ 1 (no slack variables).\n",
        "\n",
        "Pros: maximum margin yields often good generalization if perfect separability holds.\n",
        "\n",
        "Cons: not robust to noise or outliers; if data not perfectly separable, solution does not exist.\n",
        "\n",
        "Soft Margin SVM\n",
        "\n",
        "Introduces slack variables ξᵢ ≥ 0 to allow some training points to be on the wrong side of the margin or misclassified.\n",
        "\n",
        "Optimization objective becomes: minimize (1/2)||w||² + C Σ ξᵢ subject to yᵢ (wᵀxᵢ + b) ≥ 1 − ξᵢ.\n",
        "\n",
        "The hyperparameter C controls the tradeoff:\n",
        "\n",
        "Large C: penalize misclassification heavily → lower training error but potentially smaller margin (risk of overfitting).\n",
        "\n",
        "Small C: allow more misclassifications → wider margin (more regularization).\n",
        "\n",
        "Pros: robust to noise and outliers, can work on non-separable data.\n",
        "\n",
        "Soft margin is the practical default for real datasets.\n",
        "\n",
        "Key differences summarized:\n",
        "\n",
        "Existence: Hard margin requires strict linear separability; soft margin works for both separable and nonseparable.\n",
        "\n",
        "Flexibility: Soft margin handles noise/outliers via slack variables and C.\n",
        "\n",
        "Regularization: Soft margin introduces effective regularization via C.\n",
        "\n",
        "When to use which:\n",
        "\n",
        "Hard margin only for clean, perfectly separable datasets (rare in practice).\n",
        "\n",
        "Soft margin for almost all real-world problems.\n",
        "\n",
        "# Q3: What is the Kernel Trick in SVM? Give one example of a kernel and explain its use case.\n",
        "\n",
        "Answer : Kernel Trick — concept\n",
        "\n",
        "The kernel trick allows SVM to build nonlinear decision boundaries by implicitly mapping input data x into a higher-dimensional feature space φ(x) without computing φ(x) explicitly.\n",
        "\n",
        "The SVM dual problem only requires inner products between data points, φ(xᵢ)ᵀφ(xⱼ). If we define a kernel function K(xᵢ, xⱼ) = φ(xᵢ)ᵀφ(xⱼ), we can compute these inner products directly in input space using K, avoiding explicit mapping which could be computationally expensive or infinite-dimensional.\n",
        "\n",
        "This permits efficient learning of nonlinear separators as linear separators in the transformed feature space.\n",
        "\n",
        "Common kernels\n",
        "\n",
        "Linear kernel: K(x, z) = xᵀz (no mapping; equivalent to linear SVM).\n",
        "\n",
        "Polynomial kernel: K(x, z) = (γ xᵀz + r)^d — maps to polynomial feature space.\n",
        "\n",
        "Radial Basis Function (RBF) / Gaussian kernel: K(x, z) = exp(−γ||x − z||²) — infinite-dimensional mapping, very flexible.\n",
        "\n",
        "Sigmoid kernel: K(x, z) = tanh(γ xᵀz + r) — related to neural networks.\n",
        "\n",
        "Example — RBF (Gaussian) kernel and use case\n",
        "\n",
        "RBF kernel formula: K(x, z) = exp(−γ ||x − z||²), γ > 0.\n",
        "\n",
        "Properties and use cases:\n",
        "\n",
        "Allows complex decision boundaries; handles nonlinearity well.\n",
        "\n",
        "Works well when there is no prior about the form of decision boundary.\n",
        "\n",
        "Common in problems like image classification, when decision boundaries are nonlinear and high flexibility is needed.\n",
        "\n",
        "Hyperparameter γ controls locality: small γ → broader influence (smoother decision boundary), large γ → more localized influence (potentially overfitting).\n",
        "\n",
        "Choice guidance: If features are many and relationships nonlinear, RBF is a good default kernel; tune γ and C via cross-validation.\n",
        "\n",
        "Caveat: Kernel selection and hyperparameter tuning (C, γ, degree for polynomial) are crucial; try cross-validation and consider computational cost for large datasets.\n",
        "\n",
        "# Q4: What is a Naïve Bayes Classifier, and why is it called “naïve”?\n",
        "\n",
        "Answer : Naïve Bayes — concept\n",
        "\n",
        "Naïve Bayes classifiers are a family of probabilistic classifiers based on Bayes’ theorem:\n",
        "\n",
        "P(y | x) = P(x | y) P(y) / P(x)\n",
        "\n",
        "where y is a class label and x = (x₁, x₂, ..., x_d) are features.\n",
        "\n",
        "The classifier assigns a class label y that maximizes the posterior probability P(y | x). Using Bayes’ theorem and ignoring P(x) (same for all classes), we choose ŷ = argmax_y P(y) Π_i P(x_i | y).\n",
        "\n",
        "Why “naïve”?\n",
        "\n",
        "Because the model makes a strong independence assumption: it assumes that features x_i are conditionally independent given the class y. In practice, many features are correlated; this assumption is simplistic (naïve), yet the algorithm often performs surprisingly well.\n",
        "\n",
        "How it works:\n",
        "\n",
        "The model estimates prior probabilities P(y) from training data and likelihoods P(x_i | y) for each feature and class.\n",
        "\n",
        "Depending on feature type, different likelihood models are used (Gaussian for continuous, Multinomial/Bernoulli for discrete/count/text).\n",
        "\n",
        "Strengths:\n",
        "\n",
        "Very fast to train and predict, scalable to large datasets.\n",
        "\n",
        "Works well for high-dimensional data (e.g., text classification).\n",
        "\n",
        "Requires relatively little training data (simple parameter estimates).\n",
        "\n",
        "Limitations:\n",
        "\n",
        "The independence assumption can hurt when features are strongly correlated.\n",
        "\n",
        "Not flexible; model bias can limit performance in complex tasks.\n",
        "\n",
        "Use cases:\n",
        "\n",
        "Text classification (spam detection, sentiment analysis), document categorization, simple baseline classifiers for multiclass problems.\n",
        "\n",
        "# Q5: Describe the Gaussian, Multinomial, and Bernoulli Naïve Bayes variants. When would you use each one?\n",
        "\n",
        "Answer : Naïve Bayes has several variants depending on the assumed distribution of features P(x_i | y):\n",
        "\n",
        "Gaussian Naïve Bayes\n",
        "\n",
        "Assumes continuous features x_i follow a Gaussian (normal) distribution for each class:\n",
        "P(x_i | y) ~ N(μ_{y,i}, σ_{y,i}²).\n",
        "\n",
        "Estimation: compute mean and variance per feature per class from training data.\n",
        "\n",
        "Use when: features are continuous and roughly normally distributed (e.g., measurements, sensor data, some numeric features). Common for datasets like the Iris or numeric tabular data.\n",
        "\n",
        "Multinomial Naïve Bayes\n",
        "\n",
        "Models feature vectors as count vectors (nonnegative integers), treating P(x | y) as a multinomial distribution parameterized by the probability of each feature given the class.\n",
        "\n",
        "Common for bag-of-words text representations where features are word counts or term frequencies.\n",
        "\n",
        "Use when: features are counts or count-derived (e.g., word counts in documents). Often the go-to for text classification with CountVectorizer or TF counts.\n",
        "\n",
        "Bernoulli Naïve Bayes\n",
        "\n",
        "Features are binary (0/1), modeling presence/absence of features using Bernoulli distributions per feature per class.\n",
        "\n",
        "Also widely used for text where features indicate whether a word occurs in a document or not (binary bag-of-words).\n",
        "\n",
        "Use when: binary features are appropriate (word present or not), or you want to focus on occurrence instead of counts.\n",
        "\n",
        "Which to choose:\n",
        "\n",
        "For text with raw counts → MultinomialNB.\n",
        "\n",
        "For text with binary indicators (presence) → BernoulliNB.\n",
        "\n",
        "For continuous numeric features → GaussianNB."
      ],
      "metadata": {
        "id": "PpGAbssgMMWf"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sSpdCgd9MF3D",
        "outputId": "4bd9a19b-55fd-4896-d76d-19745086e320"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy on test set: 1.0000\n",
            "Number of support vectors for each class: [ 3 10  9]\n",
            "Support vector indices (relative to training set): [ 10  35  44  21  38  53  57  59  62  68 100 101 104   7   9  16  33  45\n",
            "  54  83  95 103]\n",
            "First 5 support vectors (features):\n",
            "[[5.1 3.8 1.9 0.4]\n",
            " [4.8 3.4 1.9 0.2]\n",
            " [5.  3.  1.6 0.2]\n",
            " [6.9 3.1 4.9 1.5]\n",
            " [6.  2.9 4.5 1.5]]\n"
          ]
        }
      ],
      "source": [
        "# Q6: Write a Python program to:\n",
        "# Load the Iris dataset\n",
        "# Train an SVM Classifier with a linear kernel\n",
        "# Print the model's accuracy and support vectors.\n",
        "\n",
        "from sklearn import datasets\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "import numpy as np\n",
        "\n",
        "# Load Iris\n",
        "iris = datasets.load_iris()\n",
        "X = iris.data\n",
        "y = iris.target\n",
        "\n",
        "# For simplicity, convert to a binary problem (optional) or use multiclass SVM (SVC handles multiclass with one-vs-one)\n",
        "# We'll use multiclass SVC with linear kernel.\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42, stratify=y)\n",
        "\n",
        "# Train SVM with linear kernel\n",
        "model = SVC(kernel='linear', C=1.0, random_state=42)\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Predictions and accuracy\n",
        "y_pred = model.predict(X_test)\n",
        "acc = accuracy_score(y_test, y_pred)\n",
        "\n",
        "print(f\"Accuracy on test set: {acc:.4f}\")\n",
        "print(\"Number of support vectors for each class:\", model.n_support_)\n",
        "print(\"Support vector indices (relative to training set):\", model.support_)\n",
        "# Show a few support vectors\n",
        "print(\"First 5 support vectors (features):\")\n",
        "print(model.support_vectors_[:5])"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Q7: Write a Python program to: Load the Breast Cancer dataset\n",
        "#     Train a Gaussian Naïve Bayes model\n",
        "#     Print its classification report including precision, recall, and F1-score.\n",
        "from sklearn import datasets\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report, accuracy_score\n",
        "\n",
        "# Load Breast Cancer\n",
        "data = datasets.load_breast_cancer()\n",
        "X = data.data\n",
        "y = data.target\n",
        "\n",
        "# Train-test split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42, stratify=y)\n",
        "\n",
        "# Train Gaussian Naive Bayes\n",
        "gnb = GaussianNB()\n",
        "gnb.fit(X_train, y_train)\n",
        "\n",
        "# Evaluate\n",
        "y_pred = gnb.predict(X_test)\n",
        "print(f\"Accuracy: {accuracy_score(y_test, y_pred):.4f}\\n\")\n",
        "print(\"Classification Report:\")\n",
        "print(classification_report(y_test, y_pred, target_names=data.target_names))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nx7rh5vpNdyT",
        "outputId": "b880048f-c662-4a74-bf83-df2792b31e09"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.9371\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "   malignant       0.96      0.87      0.91        53\n",
            "      benign       0.93      0.98      0.95        90\n",
            "\n",
            "    accuracy                           0.94       143\n",
            "   macro avg       0.94      0.92      0.93       143\n",
            "weighted avg       0.94      0.94      0.94       143\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Q8: Write a Python program to: Train an SVM Classifier on the Wine dataset using GridSearchCV to find the best C and gamma.\n",
        "#     Print the best hyperparameters and accuracy.\n",
        "from sklearn import datasets\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Load Wine dataset\n",
        "wine = datasets.load_wine()\n",
        "X = wine.data\n",
        "y = wine.target\n",
        "\n",
        "# Train-test split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42, stratify=y)\n",
        "\n",
        "# Define parameter grid - for RBF kernel (gamma) and C\n",
        "param_grid = {\n",
        "    'C': [0.1, 1, 10, 100],\n",
        "    'gamma': ['scale', 0.001, 0.01, 0.1, 1],\n",
        "    'kernel': ['rbf']\n",
        "}\n",
        "\n",
        "svc = SVC()\n",
        "grid = GridSearchCV(svc, param_grid, cv=5, n_jobs=-1, scoring='accuracy')\n",
        "grid.fit(X_train, y_train)\n",
        "\n",
        "best = grid.best_estimator_\n",
        "print(\"Best hyperparameters:\", grid.best_params_)\n",
        "# Evaluate on test\n",
        "y_pred = best.predict(X_test)\n",
        "print(f\"Test accuracy with best estimator: {accuracy_score(y_test, y_pred):.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MwbJ3WHNNshB",
        "outputId": "21ea339d-be07-41d9-d6ce-e429bc6c692b"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best hyperparameters: {'C': 100, 'gamma': 'scale', 'kernel': 'rbf'}\n",
            "Test accuracy with best estimator: 0.8222\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Q9: Write a Python program to: Train a Naïve Bayes Classifier on a synthetic text dataset using fetch_20newsgroups.\n",
        "#     Print the model's ROC-AUC score for its predictions.\n",
        "from sklearn.datasets import fetch_20newsgroups\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import roc_auc_score, roc_curve\n",
        "from sklearn.preprocessing import label_binarize\n",
        "import numpy as np\n",
        "\n",
        "# Select a subset of categories to make this a binary problem (for ROC-AUC)\n",
        "cats = ['sci.space', 'rec.autos']  # two categories -> binary classification\n",
        "data = fetch_20newsgroups(subset='all', categories=cats, remove=('headers', 'footers', 'quotes'))\n",
        "\n",
        "X = data.data\n",
        "y = data.target  # 0 or 1\n",
        "\n",
        "# Vectorize text with TF-IDF\n",
        "vectorizer = TfidfVectorizer(stop_words='english', max_df=0.8)\n",
        "X_vec = vectorizer.fit_transform(X)\n",
        "\n",
        "# Train-test split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_vec, y, test_size=0.25, random_state=42, stratify=y)\n",
        "\n",
        "# Train Multinomial Naive Bayes\n",
        "clf = MultinomialNB()\n",
        "clf.fit(X_train, y_train)\n",
        "\n",
        "# Predict probabilities and compute ROC-AUC\n",
        "y_proba = clf.predict_proba(X_test)[:, 1]  # probability for positive class\n",
        "roc_auc = roc_auc_score(y_test, y_proba)\n",
        "print(f\"ROC-AUC score (binary): {roc_auc:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AwhvBsOLONf-",
        "outputId": "9862efa2-4145-4a32-ce91-1eea41dc445e"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ROC-AUC score (binary): 0.9915\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        " # Q10: Imagine you’re working as a data scientist for a company that handles email communications.\n",
        " # Your task is to automatically classify emails as Spam or Not Spam. The emails may contain:\n",
        "#● Text with diverse vocabulary\n",
        "#● Potential class imbalance (far more legitimate emails than spam)\n",
        "#● Some incomplete or missing data\n",
        "#Explain the approach you would take to:\n",
        "#● Preprocess the data (e.g. text vectorization, handling missing data)\n",
        "#● Choose and justify an appropriate model (SVM vs. Naïve Bayes)\n",
        "#● Address class imbalance\n",
        "#● Evaluate the performance of your solution with suitable metrics\n",
        "#And explain the business impact of your solution.\n",
        "\n",
        "Answer : Problem characteristics:\n",
        "\n",
        "Text data with diverse vocabulary → high dimensional, sparse features.\n",
        "\n",
        "Potential class imbalance (legitimate >> spam).\n",
        "\n",
        "Missing/incomplete data possible (e.g., some emails empty or missing metadata).\n",
        "\n",
        "Overall approach (high level):\n",
        "\n",
        "Data collection & exploratory analysis\n",
        "\n",
        "Inspect missing values, distribution of classes, common tokens, length distributions, presence of HTML.\n",
        "\n",
        "Preprocessing\n",
        "\n",
        "Clean text (remove headers/footers if present, strip HTML tags, lowercasing).\n",
        "\n",
        "Replace missing/empty emails with a placeholder or drop (depending on proportion).\n",
        "\n",
        "Tokenization and vectorization using TfidfVectorizer (handles large sparse text well).\n",
        "\n",
        "Consider additional features: sender domain, number of links, presence of attachments, suspicious tokens (e.g., “free”, “win”), ratio of uppercase words.\n",
        "\n",
        "Feature engineering\n",
        "\n",
        "Use n-grams (unigrams + bigrams) for richer text patterns.\n",
        "\n",
        "Limit vocabulary with max_df/min_df to remove very rare/noisy tokens.\n",
        "\n",
        "Scaling not necessary for Naïve Bayes; for SVM, sparse TF-IDF can be used directly with linear SVM\n",
        "\n",
        "Model choice (SVM vs Naïve Bayes)\n",
        "\n",
        "Naïve Bayes (MultinomialNB): fast, works well on text (counts or TF). Often a strong baseline for spam detection and handles large vocabularies efficiently. Robust to high-dimensional sparsity.\n",
        "\n",
        "SVM (LinearSVC): often yields higher accuracy when tuned, especially with TF-IDF. More computationally intensive but can handle high-dimensional data. Use LinearSVC for scalability.\n",
        "\n",
        "Recommendation: start with MultinomialNB as baseline (fast). Then train LinearSVC with cross-validation; compare metrics (precision/recall/F1/AUC). For production, a linear SVM or a calibrated SVM (probability estimates via CalibratedClassifierCV) may be preferred if performance gains justify the cost.\n",
        "\n",
        "Class imbalance handling\n",
        "\n",
        "Techniques: class weights (e.g., class_weight='balanced' in SVM), resampling (SMOTE for numeric features, but for text: oversample minority class with simple replication or use RandomOverSampler on transformed features), threshold tuning, and use of appropriate evaluation metrics.\n",
        "\n",
        "For MultinomialNB, oversampling (replication) or adjusting class priors can help.\n",
        "\n",
        "Evaluation metrics\n",
        "\n",
        "Since spam detection often values catching spam while avoiding false positives, metrics:\n",
        "\n",
        "Precision (spam): proportion of predicted spam that are actual spam (reducing false positives).\n",
        "\n",
        "Recall (spam): proportion of actual spam detected (reducing false negatives).\n",
        "\n",
        "F1-score: harmonic mean of precision & recall.\n",
        "\n",
        "ROC-AUC / PR-AUC: ROC for overall discrimination, PR curve useful on imbalanced datasets.\n",
        "\n",
        "Confusion matrix: for business decisions (cost of false positives vs false negatives).\n",
        "\n",
        "In business, often prefer high precision (avoid flagging legit emails as spam) even at cost of some recall; may tune detection threshold to achieve desired tradeoff.\n",
        "\n",
        "Model deployment & monitoring\n",
        "\n",
        "Retrain periodically to capture drifting spam vocabulary.\n",
        "\n",
        "Monitor false positive rates and user feedback; allow users to mark emails as not-spam and feed back for retraining.\n",
        "\n",
        "Business impact\n",
        "\n",
        "Automated spam detection reduces user annoyance, increases productivity, and can prevent phishing/fraud losses.\n",
        "\n",
        "False positives (legitimate email flagged as spam) can cause business disruption — must be minimized (high precision).\n",
        "\n",
        "Correct spam detection reduces storage, bandwidth, and risk of malware/phishing, improving operational costs and security posture."
      ],
      "metadata": {
        "id": "QtV4ApnpaUpH"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ji_Wj2qdZodz"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}